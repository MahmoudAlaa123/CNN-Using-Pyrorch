{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.ImageFolder(\"C:/Users/EGYPT_LAPTOP/Desktop/chest_xray/train\", transform = transformations)\n",
    "test_set = datasets.ImageFolder(\"C:/Users/EGYPT_LAPTOP/Desktop/chest_xray/test\", transform = transformations)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32,drop_last = True, shuffle=True,num_workers=3)\n",
    "val_loader  = torch.utils.data.DataLoader(test_set, batch_size =32,drop_last = True, shuffle=True,num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet161(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier_input = model.classifier.in_features\n",
    "num_labels = \n",
    "classifier = nn.Sequential(nn.Linear(classifier_input, 1024),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(1024, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(512, num_labels),\n",
    "                           nn.LogSoftmax(dim=1))\n",
    "# Replace default classifier with new classifier\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2208"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2208, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the device available to use using torch library\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Move model to the device specified above\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the error function using torch.nn as nn library\n",
    "weight = torch.Tensor([0.74,0.24])\n",
    "criterion = nn.NLLLoss(weight= weight).to(device)\n",
    "# Set the optimizer function using torch.optim as optim library\n",
    "optimizer = optim.Adam(model.classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EGYPT_LAPTOP\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8519736842105263\n",
      "Epoch: 0 \tTraining Loss: 0.229418 \tValidation Loss: 0.851995\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.881578947368421\n",
      "Epoch: 1 \tTraining Loss: 0.159503 \tValidation Loss: 0.567877\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8930921052631579\n",
      "Epoch: 2 \tTraining Loss: 0.114591 \tValidation Loss: 0.488999\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.875\n",
      "Epoch: 3 \tTraining Loss: 0.110976 \tValidation Loss: 0.736544\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8782894736842105\n",
      "Epoch: 4 \tTraining Loss: 0.132321 \tValidation Loss: 0.839189\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8782894736842105\n",
      "Epoch: 5 \tTraining Loss: 0.102021 \tValidation Loss: 0.936627\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8881578947368421\n",
      "Epoch: 6 \tTraining Loss: 0.103062 \tValidation Loss: 0.821419\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8585526315789473\n",
      "Epoch: 7 \tTraining Loss: 0.097997 \tValidation Loss: 1.003215\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8519736842105263\n",
      "Epoch: 8 \tTraining Loss: 0.085013 \tValidation Loss: 1.154857\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8799342105263158\n",
      "Epoch: 9 \tTraining Loss: 0.098498 \tValidation Loss: 0.824933\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8519736842105263\n",
      "Epoch: 10 \tTraining Loss: 0.085303 \tValidation Loss: 1.069464\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8536184210526315\n",
      "Epoch: 11 \tTraining Loss: 0.107567 \tValidation Loss: 0.822563\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8601973684210527\n",
      "Epoch: 12 \tTraining Loss: 0.067846 \tValidation Loss: 1.305125\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8733552631578947\n",
      "Epoch: 13 \tTraining Loss: 0.068641 \tValidation Loss: 1.120192\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.881578947368421\n",
      "Epoch: 14 \tTraining Loss: 0.079793 \tValidation Loss: 0.661709\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.868421052631579\n",
      "Epoch: 15 \tTraining Loss: 0.063756 \tValidation Loss: 0.952956\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8832236842105263\n",
      "Epoch: 16 \tTraining Loss: 0.070849 \tValidation Loss: 1.063607\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8700657894736842\n",
      "Epoch: 17 \tTraining Loss: 0.058236 \tValidation Loss: 1.167508\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8601973684210527\n",
      "Epoch: 18 \tTraining Loss: 0.055040 \tValidation Loss: 1.185940\n",
      "1 / 163\n",
      "2 / 163\n",
      "3 / 163\n",
      "4 / 163\n",
      "5 / 163\n",
      "6 / 163\n",
      "7 / 163\n",
      "8 / 163\n",
      "9 / 163\n",
      "10 / 163\n",
      "11 / 163\n",
      "12 / 163\n",
      "13 / 163\n",
      "14 / 163\n",
      "15 / 163\n",
      "16 / 163\n",
      "17 / 163\n",
      "18 / 163\n",
      "19 / 163\n",
      "20 / 163\n",
      "21 / 163\n",
      "22 / 163\n",
      "23 / 163\n",
      "24 / 163\n",
      "25 / 163\n",
      "26 / 163\n",
      "27 / 163\n",
      "28 / 163\n",
      "29 / 163\n",
      "30 / 163\n",
      "31 / 163\n",
      "32 / 163\n",
      "33 / 163\n",
      "34 / 163\n",
      "35 / 163\n",
      "36 / 163\n",
      "37 / 163\n",
      "38 / 163\n",
      "39 / 163\n",
      "40 / 163\n",
      "41 / 163\n",
      "42 / 163\n",
      "43 / 163\n",
      "44 / 163\n",
      "45 / 163\n",
      "46 / 163\n",
      "47 / 163\n",
      "48 / 163\n",
      "49 / 163\n",
      "50 / 163\n",
      "51 / 163\n",
      "52 / 163\n",
      "53 / 163\n",
      "54 / 163\n",
      "55 / 163\n",
      "56 / 163\n",
      "57 / 163\n",
      "58 / 163\n",
      "59 / 163\n",
      "60 / 163\n",
      "61 / 163\n",
      "62 / 163\n",
      "63 / 163\n",
      "64 / 163\n",
      "65 / 163\n",
      "66 / 163\n",
      "67 / 163\n",
      "68 / 163\n",
      "69 / 163\n",
      "70 / 163\n",
      "71 / 163\n",
      "72 / 163\n",
      "73 / 163\n",
      "74 / 163\n",
      "75 / 163\n",
      "76 / 163\n",
      "77 / 163\n",
      "78 / 163\n",
      "79 / 163\n",
      "80 / 163\n",
      "81 / 163\n",
      "82 / 163\n",
      "83 / 163\n",
      "84 / 163\n",
      "85 / 163\n",
      "86 / 163\n",
      "87 / 163\n",
      "88 / 163\n",
      "89 / 163\n",
      "90 / 163\n",
      "91 / 163\n",
      "92 / 163\n",
      "93 / 163\n",
      "94 / 163\n",
      "95 / 163\n",
      "96 / 163\n",
      "97 / 163\n",
      "98 / 163\n",
      "99 / 163\n",
      "100 / 163\n",
      "101 / 163\n",
      "102 / 163\n",
      "103 / 163\n",
      "104 / 163\n",
      "105 / 163\n",
      "106 / 163\n",
      "107 / 163\n",
      "108 / 163\n",
      "109 / 163\n",
      "110 / 163\n",
      "111 / 163\n",
      "112 / 163\n",
      "113 / 163\n",
      "114 / 163\n",
      "115 / 163\n",
      "116 / 163\n",
      "117 / 163\n",
      "118 / 163\n",
      "119 / 163\n",
      "120 / 163\n",
      "121 / 163\n",
      "122 / 163\n",
      "123 / 163\n",
      "124 / 163\n",
      "125 / 163\n",
      "126 / 163\n",
      "127 / 163\n",
      "128 / 163\n",
      "129 / 163\n",
      "130 / 163\n",
      "131 / 163\n",
      "132 / 163\n",
      "133 / 163\n",
      "134 / 163\n",
      "135 / 163\n",
      "136 / 163\n",
      "137 / 163\n",
      "138 / 163\n",
      "139 / 163\n",
      "140 / 163\n",
      "141 / 163\n",
      "142 / 163\n",
      "143 / 163\n",
      "144 / 163\n",
      "145 / 163\n",
      "146 / 163\n",
      "147 / 163\n",
      "148 / 163\n",
      "149 / 163\n",
      "150 / 163\n",
      "151 / 163\n",
      "152 / 163\n",
      "153 / 163\n",
      "154 / 163\n",
      "155 / 163\n",
      "156 / 163\n",
      "157 / 163\n",
      "158 / 163\n",
      "159 / 163\n",
      "160 / 163\n",
      "161 / 163\n",
      "162 / 163\n",
      "163 / 163\n",
      "1 / 19\n",
      "2 / 19\n",
      "3 / 19\n",
      "4 / 19\n",
      "5 / 19\n",
      "6 / 19\n",
      "7 / 19\n",
      "8 / 19\n",
      "9 / 19\n",
      "10 / 19\n",
      "11 / 19\n",
      "12 / 19\n",
      "13 / 19\n",
      "14 / 19\n",
      "15 / 19\n",
      "16 / 19\n",
      "17 / 19\n",
      "18 / 19\n",
      "19 / 19\n",
      "Accuracy:  0.8667763157894737\n",
      "Epoch: 19 \tTraining Loss: 0.043069 \tValidation Loss: 1.243674\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Training the model\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "       \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        output = model.forward(inputs)\n",
    "       \n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "     \n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "        \n",
    "       \n",
    "        counter += 1\n",
    "        print(counter, \"/\", len(train_loader))\n",
    "        \n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model.forward(inputs)\n",
    "            valloss = criterion(output, labels)\n",
    "            val_loss += valloss.item()*inputs.size(0)\n",
    "           \n",
    "            output = torch.exp(output)\n",
    "            top_p, top_class = output.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            \n",
    "            counter += 1\n",
    "            print(counter, \"/\", len(val_loader))\n",
    "    \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = val_loss/len(val_loader.dataset)\n",
    "    print('Accuracy: ', accuracy/len(val_loader))\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
